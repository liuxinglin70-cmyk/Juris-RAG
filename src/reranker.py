"""
Juris-RAG Reranker æ¨¡å—
åŸºäºLLMçš„æ–‡æ¡£é‡æ’åºå’Œè¶…èŒƒå›´åˆ¤åˆ«å™¨
ç”¨äºï¼š
1. å¯¹æ£€ç´¢ç»“æœè¿›è¡Œç›¸å…³æ€§é‡æ’åº
2. æ£€æµ‹è¶…èŒƒå›´é—®é¢˜ï¼ˆäºŒæ¬¡éªŒè¯ï¼‰
3. æ£€æµ‹æ½œåœ¨å¹»è§‰é£é™©
"""
import os
import re
import json
import hashlib
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from functools import lru_cache
from collections import OrderedDict
import time
import threading

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage
    from langchain_core.documents import Document
except ImportError:
    from langchain_community.chat_models import ChatOpenAI
    from langchain.schema import HumanMessage, SystemMessage, Document

# å¯¼å…¥é…ç½®
try:
    from src.config import (
        SILICONFLOW_API_KEY, SILICONFLOW_BASE_URL,
        RERANKER_MODEL, RERANKER_TOP_K, RERANKER_THRESHOLD,
        ENABLE_RERANKER, ENABLE_HALLUCINATION_CHECK,
        ENABLE_CACHE, CACHE_MAX_SIZE, CACHE_TTL_SECONDS,
        LLM_MODEL
    )
except ImportError:
    SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
    SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"
    RERANKER_MODEL = "Qwen/Qwen3-8B"
    LLM_MODEL = "Qwen/Qwen3-8B"
    RERANKER_TOP_K = 5
    RERANKER_THRESHOLD = 0.4
    ENABLE_RERANKER = True
    ENABLE_HALLUCINATION_CHECK = True
    ENABLE_CACHE = True
    CACHE_MAX_SIZE = 100
    CACHE_TTL_SECONDS = 3600


@dataclass
class RerankedDocument:
    """é‡æ’åºåçš„æ–‡æ¡£"""
    document: Document
    relevance_score: float
    is_relevant: bool
    reasoning: str = ""


@dataclass
class ScopeCheckResult:
    """è¶…èŒƒå›´æ£€æµ‹ç»“æœ"""
    is_in_scope: bool
    confidence: float
    detected_domain: str
    reasoning: str


@dataclass
class HallucinationCheckResult:
    """å¹»è§‰æ£€æµ‹ç»“æœ"""
    has_hallucination_risk: bool
    risk_level: str  # low, medium, high
    problematic_claims: List[str]
    reasoning: str


class TTLCache:
    """å¸¦è¿‡æœŸæ—¶é—´çš„LRUç¼“å­˜"""
    
    def __init__(self, max_size: int = 100, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache: OrderedDict = OrderedDict()
        self.timestamps: Dict[str, float] = {}
        self.lock = threading.Lock()
    
    def _generate_key(self, *args) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = json.dumps(args, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[any]:
        """è·å–ç¼“å­˜å€¼"""
        with self.lock:
            if key not in self.cache:
                return None
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() - self.timestamps[key] > self.ttl_seconds:
                del self.cache[key]
                del self.timestamps[key]
                return None
            
            # ç§»åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            self.cache.move_to_end(key)
            return self.cache[key]
    
    def set(self, key: str, value: any):
        """è®¾ç½®ç¼“å­˜å€¼"""
        with self.lock:
            # å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°
            if key in self.cache:
                self.cache[key] = value
                self.timestamps[key] = time.time()
                self.cache.move_to_end(key)
                return
            
            # å¦‚æœè¶…å‡ºå¤§å°é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„
            while len(self.cache) >= self.max_size:
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                del self.timestamps[oldest_key]
            
            self.cache[key] = value
            self.timestamps[key] = time.time()
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.timestamps.clear()


class LLMReranker:
    """åŸºäºLLMçš„é‡æ’åºå™¨å’Œåˆ¤åˆ«å™¨"""
    
    def __init__(self):
        if not SILICONFLOW_API_KEY:
            raise ValueError("âŒ æœªæ‰¾åˆ° SILICONFLOW_API_KEY")
        
        self.llm = ChatOpenAI(
            model=RERANKER_MODEL if RERANKER_MODEL else LLM_MODEL,
            temperature=0.0,  # ç¡®å®šæ€§è¾“å‡º
            max_tokens=512,
            openai_api_base=SILICONFLOW_BASE_URL,
            openai_api_key=SILICONFLOW_API_KEY
        )
        
        # åˆå§‹åŒ–ç¼“å­˜
        if ENABLE_CACHE:
            self.cache = TTLCache(max_size=CACHE_MAX_SIZE, ttl_seconds=CACHE_TTL_SECONDS)
        else:
            self.cache = None
    
    def rerank_documents(
        self, 
        query: str, 
        documents: List[Document], 
        top_k: int = None
    ) -> List[RerankedDocument]:
        """
        å¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œé‡æ’åº
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            documents: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
            top_k: ä¿ç•™çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not ENABLE_RERANKER or not documents:
            # ä¸å¯ç”¨é‡æ’åºï¼Œç›´æ¥è¿”å›åŸå§‹æ–‡æ¡£
            return [
                RerankedDocument(
                    document=doc,
                    relevance_score=1.0 - min(doc.metadata.get("relevance_score", 0.5) / 2, 1.0),
                    is_relevant=True
                )
                for doc in documents
            ]
        
        top_k = top_k or RERANKER_TOP_K
        
        # æ£€æŸ¥ç¼“å­˜
        if self.cache:
            cache_key = self.cache._generate_key(query, [d.page_content[:100] for d in documents[:10]])
            cached_result = self.cache.get(cache_key)
            if cached_result:
                return cached_result[:top_k]
        
        # æ„å»ºé‡æ’åºæç¤ºè¯
        docs_text = ""
        for i, doc in enumerate(documents[:10]):  # æœ€å¤šå¤„ç†10ä¸ªæ–‡æ¡£
            doc_type = doc.metadata.get("type", "unknown")
            source = doc.metadata.get("source", "æœªçŸ¥")
            content = doc.page_content[:300]
            docs_text += f"[æ–‡æ¡£{i+1}] ç±»å‹:{doc_type} æ¥æº:{source}\n{content}\n\n"
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹æ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æ¡£ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³æ€§ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

ã€å€™é€‰æ–‡æ¡£ã€‘
{docs_text}

ã€è¯„ä¼°è¦æ±‚ã€‘
1. ä¸ºæ¯ä¸ªæ–‡æ¡£è¯„åˆ†ï¼ˆ0-10åˆ†ï¼Œ10åˆ†æœ€ç›¸å…³ï¼‰
2. åˆ¤æ–­æ–‡æ¡£æ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼ˆæ˜¯/å¦ï¼‰
3. ä¼˜å…ˆè€ƒè™‘ç›´æ¥å›ç­”é—®é¢˜çš„æ³•æ¡æ–‡æ¡£

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼æŒ‰JSONæ ¼å¼ï¼‰
{{
  "rankings": [
    {{"doc_id": 1, "score": 8, "relevant": true}},
    {{"doc_id": 2, "score": 5, "relevant": true}},
    ...
  ]
}}

è¯·åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result_text = response.content.strip()
            
            # è§£æJSON
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
                rankings = result.get("rankings", [])
                
                # æ„å»ºé‡æ’åºç»“æœ
                reranked = []
                doc_scores = {r["doc_id"]: r for r in rankings}
                
                for i, doc in enumerate(documents[:10]):
                    score_info = doc_scores.get(i + 1, {"score": 5, "relevant": True})
                    normalized_score = score_info["score"] / 10.0
                    
                    reranked.append(RerankedDocument(
                        document=doc,
                        relevance_score=normalized_score,
                        is_relevant=score_info.get("relevant", True) and normalized_score >= RERANKER_THRESHOLD
                    ))
                
                # æŒ‰åˆ†æ•°æ’åº
                reranked.sort(key=lambda x: x.relevance_score, reverse=True)
                
                # ç¼“å­˜ç»“æœ
                if self.cache:
                    self.cache.set(cache_key, reranked)
                
                return reranked[:top_k]
                
        except Exception as e:
            print(f"[Reranker] é‡æ’åºå¤±è´¥: {e}")
        
        # å¤±è´¥æ—¶è¿”å›åŸå§‹é¡ºåº
        return [
            RerankedDocument(
                document=doc,
                relevance_score=1.0 - min(doc.metadata.get("relevance_score", 0.5) / 2, 1.0),
                is_relevant=True
            )
            for doc in documents[:top_k]
        ]
    
    def check_scope(self, query: str) -> ScopeCheckResult:
        """
        ä½¿ç”¨LLMæ£€æµ‹é—®é¢˜æ˜¯å¦åœ¨åˆ‘æ³•èŒƒå›´å†…ï¼ˆäºŒæ¬¡éªŒè¯ï¼‰
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            
        Returns:
            è¶…èŒƒå›´æ£€æµ‹ç»“æœ
        """
        # æ£€æŸ¥ç¼“å­˜
        if self.cache:
            cache_key = self.cache._generate_key("scope_check", query)
            cached_result = self.cache.get(cache_key)
            if cached_result:
                return cached_result
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹é¢†åŸŸåˆ†ç±»ä¸“å®¶ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹é—®é¢˜å±äºå“ªä¸ªæ³•å¾‹é¢†åŸŸã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

ã€æ³•å¾‹é¢†åŸŸåˆ†ç±»ã€‘
1. åˆ‘æ³•ï¼šçŠ¯ç½ªã€åˆ‘ç½šã€åˆ‘äº‹è´£ä»»ã€æ•…æ„æ€äººã€ç›—çªƒã€è¯ˆéª—ã€å¼ºå¥¸ã€èµ°ç§ç­‰åˆ‘äº‹çŠ¯ç½ª
2. æ°‘æ³•ï¼šåˆåŒã€å©šå§»ã€ç»§æ‰¿ã€ç‰©æƒã€ä¾µæƒã€å€ºåŠ¡ç­‰æ°‘äº‹å…³ç³»
3. å•†æ³•ï¼šå…¬å¸ã€è¯åˆ¸ã€ä¿é™©ã€ç¥¨æ®ã€ç ´äº§ç­‰å•†ä¸šäº‹åŠ¡
4. è¡Œæ”¿æ³•ï¼šè¡Œæ”¿å¤„ç½šã€è¡Œæ”¿å¤è®®ã€è¡Œæ”¿è¯‰è®¼ç­‰è¡Œæ”¿ç®¡ç†
5. åŠ³åŠ¨æ³•ï¼šåŠ³åŠ¨åˆåŒã€ç¤¾ä¿ã€å·¥ä¼¤ã€åŠ³åŠ¨ä»²è£ç­‰åŠ³åŠ¨å…³ç³»
6. å…¶ä»–ï¼šç¨æ³•ã€çŸ¥è¯†äº§æƒã€ç¯ä¿ç­‰å…¶ä»–é¢†åŸŸ
7. éæ³•å¾‹ï¼šä¸æ³•å¾‹æ— å…³çš„é—®é¢˜

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆJSONï¼‰
{{
  "domain": "åˆ‘æ³•/æ°‘æ³•/å•†æ³•/è¡Œæ”¿æ³•/åŠ³åŠ¨æ³•/å…¶ä»–/éæ³•å¾‹",
  "confidence": 0.95,
  "reasoning": "ç®€è¦è¯´æ˜åˆ¤æ–­ç†ç”±"
}}

è¯·åªè¾“å‡ºJSONã€‚"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result_text = response.content.strip()
            
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
                domain = result.get("domain", "åˆ‘æ³•")
                confidence = result.get("confidence", 0.5)
                reasoning = result.get("reasoning", "")
                
                # åˆ‘æ³•é¢†åŸŸè§†ä¸ºåœ¨èŒƒå›´å†…
                is_in_scope = domain == "åˆ‘æ³•"
                
                check_result = ScopeCheckResult(
                    is_in_scope=is_in_scope,
                    confidence=confidence,
                    detected_domain=domain,
                    reasoning=reasoning
                )
                
                # ç¼“å­˜ç»“æœ
                if self.cache:
                    self.cache.set(cache_key, check_result)
                
                return check_result
                
        except Exception as e:
            print(f"[Reranker] èŒƒå›´æ£€æµ‹å¤±è´¥: {e}")
        
        # é»˜è®¤è®¤ä¸ºåœ¨èŒƒå›´å†…
        return ScopeCheckResult(
            is_in_scope=True,
            confidence=0.5,
            detected_domain="æœªçŸ¥",
            reasoning="æ£€æµ‹å¤±è´¥ï¼Œé»˜è®¤åœ¨èŒƒå›´å†…"
        )
    
    def _check_hallucination_local(
        self,
        query: str,
        answer: str,
        retrieved_docs: List[Document]
    ) -> HallucinationCheckResult:
        """
        ã€æ–¹æ¡ˆBã€‘æœ¬åœ°å¿«é€Ÿå¹»è§‰æ£€æµ‹ - ä¸è°ƒç”¨LLMï¼Œä½¿ç”¨å¯å‘å¼è§„åˆ™
        æ›´å¿«é€Ÿï¼Œé€‚åˆå¯¹æ­£å¸¸é—®é¢˜çš„å¿«é€Ÿæ£€æµ‹
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            answer: ç”Ÿæˆçš„å›ç­”
            retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£
            
        Returns:
            å¹»è§‰æ£€æµ‹ç»“æœ
        """
        problematic_claims = []
        risk_level = "low"
        
        # æå–æ£€ç´¢æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯
        context_text = " ".join([doc.page_content[:300] for doc in retrieved_docs[:3]])
        context_text_lower = context_text.lower()
        answer_lower = answer.lower()
        
        # å¯å‘å¼è§„åˆ™1ï¼šæ£€æŸ¥æ³•æ¡ç¼–å·
        # æå–ç­”æ¡ˆä¸­çš„æ³•æ¡ç¼–å·ï¼ˆå¦‚"ç¬¬232æ¡"ï¼‰
        law_articles = re.findall(r'ç¬¬[0-9]+æ¡', answer)
        for article in law_articles:
            if article not in context_text and len(context_text) > 100:
                # ç­”æ¡ˆä¸­æåˆ°çš„æ³•æ¡ä¸åœ¨æ£€ç´¢ç»“æœä¸­
                problematic_claims.append(f"æ³•æ¡ {article} å¯èƒ½ä¸åœ¨æ£€ç´¢ç»“æœä¸­")
        
        # å¯å‘å¼è§„åˆ™2ï¼šæ£€æŸ¥é‡åˆ‘æ ‡å‡†çš„ä¸€è‡´æ€§
        # æå–ç­”æ¡ˆä¸­çš„æ•°å­—ï¼ˆå¹´ä»½ã€æœŸæ•°ç­‰ï¼‰
        answer_numbers = re.findall(r'\d+å¹´|æ­»åˆ‘|æ— æœŸ|æœ‰æœŸ', answer)
        context_numbers = re.findall(r'\d+å¹´|æ­»åˆ‘|æ— æœŸ|æœ‰æœŸ', context_text)
        
        # å¦‚æœç­”æ¡ˆä¸­æœ‰æ˜æ˜¾çš„é‡åˆ‘ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦ä¸æ£€ç´¢å†…å®¹æœ‰é‡å 
        if answer_numbers and context_numbers:
            overlap = set(answer_numbers) & set(context_numbers)
            if not overlap and len(context_numbers) > 0:
                problematic_claims.append("é‡åˆ‘æ ‡å‡†å¯èƒ½ä¸æ£€ç´¢å†…å®¹ä¸ä¸€è‡´")
        
        # å¯å‘å¼è§„åˆ™3ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„"åˆ›é€ æ€§"ä¿¡æ¯
        # æŸ¥æ‰¾ä»¥ä¸‹æ¨¡å¼ï¼šå‡è®¾ã€å¦‚æœã€æ®è¯´ç­‰ä¸ç¡®å®šçš„è¡¨è¿°
        uncertain_patterns = r'(æ®è¯´|å¯èƒ½|å¬è¯´|å¤§æ¦‚|å¥½åƒ|ä¼¼ä¹|å‡è®¾|å¦‚æœ)'
        if re.search(uncertain_patterns, answer):
            risk_level = "medium"
        
        # å¯å‘å¼è§„åˆ™4ï¼šç­”æ¡ˆè¿‡é•¿ä¸”æ£€ç´¢æ–‡æ¡£å¾ˆå°‘ï¼Œå¯èƒ½æœ‰å¡«å……
        if len(answer) > 1000 and len(retrieved_docs) < 2:
            problematic_claims.append("ç­”æ¡ˆè¾ƒé•¿ä½†æ£€ç´¢æ–‡æ¡£è¾ƒå°‘ï¼Œå¯èƒ½åŒ…å«æ¨æ–­ä¿¡æ¯")
            risk_level = "medium"
        
        return HallucinationCheckResult(
            has_hallucination_risk=risk_level in ["medium", "high"],
            risk_level=risk_level,
            problematic_claims=problematic_claims,
            reasoning="åŸºäºå¯å‘å¼è§„åˆ™çš„æœ¬åœ°æ£€æµ‹"
        )
    
    def check_hallucination(
        self, 
        query: str, 
        answer: str, 
        retrieved_docs: List[Document],
        use_llm: bool = False
    ) -> HallucinationCheckResult:
        """
        æ£€æµ‹å›ç­”ä¸­çš„æ½œåœ¨å¹»è§‰
        
        ã€æ–¹æ¡ˆBä¼˜åŒ–ã€‘æ”¯æŒé€‰æ‹©æœ¬åœ°å¿«é€Ÿæ£€æµ‹æˆ–LLMæ·±åº¦æ£€æµ‹
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            answer: ç”Ÿæˆçš„å›ç­”
            retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£
            use_llm: æ˜¯å¦ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦æ£€æµ‹ï¼ˆæ¯”è¾ƒæ…¢ï¼‰
            
        Returns:
            å¹»è§‰æ£€æµ‹ç»“æœ
        """
        if not ENABLE_HALLUCINATION_CHECK:
            return HallucinationCheckResult(
                has_hallucination_risk=False,
                risk_level="low",
                problematic_claims=[],
                reasoning="å¹»è§‰æ£€æµ‹å·²ç¦ç”¨"
            )
        
        # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°å¿«é€Ÿæ£€æµ‹ï¼ˆé»˜è®¤ï¼‰
        if not use_llm:
            return self._check_hallucination_local(query, answer, retrieved_docs)
        
        # å¦‚æœæŒ‡å®šuse_llm=Trueï¼Œä½¿ç”¨LLMæ·±åº¦æ£€æµ‹
        # æ„å»ºæ£€ç´¢å†…å®¹æ‘˜è¦
        context_summary = ""
        for i, doc in enumerate(retrieved_docs[:5]):
            content = doc.page_content[:200]
            context_summary += f"[æ¥æº{i+1}] {content}...\n"
        
        prompt = f"""ä½ æ˜¯æ³•å¾‹äº‹å®æ ¸æŸ¥ä¸“å®¶ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹å›ç­”æ˜¯å¦å­˜åœ¨å¹»è§‰ï¼ˆä¸æ£€ç´¢å†…å®¹ä¸ç¬¦çš„ä¿¡æ¯ï¼‰ã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

ã€æ£€ç´¢åˆ°çš„æ³•å¾‹æ–‡çŒ®ã€‘
{context_summary}

ã€ç”Ÿæˆçš„å›ç­”ã€‘
{answer[:800]}

ã€æ£€æŸ¥è¦æ±‚ã€‘
1. æ£€æŸ¥å›ç­”ä¸­çš„æ³•æ¡ç¼–å·æ˜¯å¦ä¸æ£€ç´¢å†…å®¹ä¸€è‡´
2. æ£€æŸ¥é‡åˆ‘æ ‡å‡†æ˜¯å¦ä¸æ£€ç´¢å†…å®¹ä¸€è‡´
3. æ£€æŸ¥æ˜¯å¦æœ‰æ£€ç´¢å†…å®¹ä¸­æ²¡æœ‰çš„"åˆ›é€ æ€§"ä¿¡æ¯

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆJSONï¼‰
{{
  "risk_level": "low/medium/high",
  "problematic_claims": ["é—®é¢˜é™ˆè¿°1", "é—®é¢˜é™ˆè¿°2"],
  "reasoning": "åˆ¤æ–­ç†ç”±"
}}

è¯·åªè¾“å‡ºJSONã€‚"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result_text = response.content.strip()
            
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
                risk_level = result.get("risk_level", "low")
                problematic_claims = result.get("problematic_claims", [])
                reasoning = result.get("reasoning", "")
                
                return HallucinationCheckResult(
                    has_hallucination_risk=risk_level in ["medium", "high"],
                    risk_level=risk_level,
                    problematic_claims=problematic_claims,
                    reasoning=reasoning
                )
                
        except Exception as e:
            print(f"[Reranker] LLMå¹»è§‰æ£€æµ‹å¤±è´¥: {e}")
            # å›é€€åˆ°æœ¬åœ°æ£€æµ‹
            return self._check_hallucination_local(query, answer, retrieved_docs)
        
        return HallucinationCheckResult(
            has_hallucination_risk=False,
            risk_level="low",
            problematic_claims=[],
            reasoning="æ£€æµ‹å¤±è´¥"
        )


# å•ä¾‹æ¨¡å¼
_reranker_instance: Optional[LLMReranker] = None

def get_reranker() -> LLMReranker:
    """è·å–é‡æ’åºå™¨å•ä¾‹"""
    global _reranker_instance
    if _reranker_instance is None:
        _reranker_instance = LLMReranker()
    return _reranker_instance


# ä¾¿æ·å‡½æ•°
def rerank_documents(query: str, documents: List[Document], top_k: int = None) -> List[RerankedDocument]:
    """ä¾¿æ·å‡½æ•°ï¼šé‡æ’åºæ–‡æ¡£"""
    return get_reranker().rerank_documents(query, documents, top_k)


def check_scope(query: str) -> ScopeCheckResult:
    """ä¾¿æ·å‡½æ•°ï¼šæ£€æµ‹èŒƒå›´"""
    return get_reranker().check_scope(query)


def check_hallucination(query: str, answer: str, docs: List[Document], use_llm: bool = False) -> HallucinationCheckResult:
    """ä¾¿æ·å‡½æ•°ï¼šæ£€æµ‹å¹»è§‰
    
    Args:
        query: ç”¨æˆ·é—®é¢˜
        answer: ç”Ÿæˆçš„å›ç­”
        docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£
        use_llm: æ˜¯å¦ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦æ£€æµ‹ï¼ˆé»˜è®¤ä½¿ç”¨æœ¬åœ°å¿«é€Ÿæ£€æµ‹ï¼‰
    """
    return get_reranker().check_hallucination(query, answer, docs, use_llm=use_llm)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯• Reranker æ¨¡å—...")
    
    try:
        reranker = get_reranker()
        
        # æµ‹è¯•èŒƒå›´æ£€æµ‹
        test_queries = [
            "æ•…æ„æ€äººç½ªæ€ä¹ˆåˆ¤åˆ‘ï¼Ÿ",
            "ç¦»å©šè´¢äº§æ€ä¹ˆåˆ†å‰²ï¼Ÿ",
            "å…¬å¸è‚¡æƒè½¬è®©æ€ä¹ˆåŠç†ï¼Ÿ",
            "èµ°ç§æ¯’å“åˆ¤å‡ å¹´ï¼Ÿ"
        ]
        
        print("\nğŸ“Œ èŒƒå›´æ£€æµ‹æµ‹è¯•ï¼š")
        for q in test_queries:
            result = reranker.check_scope(q)
            status = "âœ…" if result.is_in_scope else "âŒ"
            print(f"{status} [{result.detected_domain}] {q}")
            print(f"   ç½®ä¿¡åº¦: {result.confidence:.2f}, ç†ç”±: {result.reasoning}")
        
        print("\nâœ… Reranker æ¨¡å—æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
